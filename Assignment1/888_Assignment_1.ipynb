{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "888 Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrA2BmmTUQLhju63Bqa5ur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vallabhvrao/CE888/blob/main/Assignment1/888_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA_mxGFd4AOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326c73cd-8d86-46df-ed32-36c66fcbccc2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/gdrive\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59na4syDYiky"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZFoFP8BbI-3",
        "outputId": "162e5d2f-891e-4b74-f3a3-dba917d7b250"
      },
      "source": [
        "import os\r\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/Data/')  #change dir\r\n",
        "!unzip -q Training.zip  #unzip data in train/\r\n",
        "!unzip -q Test.zip  #unzip data in test/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace Test/Fire/resized_test_fire_frame1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXLG2XCxlMM-",
        "outputId": "6aa67ec4-2923-41c8-de6a-2918c2ec308f"
      },
      "source": [
        "!ls -l ./Training/Fire | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY9LzA6mkTNA"
      },
      "source": [
        "data_dir = '/content/gdrive/My Drive/Colab Notebooks/Data/Training'\r\n",
        "batch_size = 32\r\n",
        "img_height = 180\r\n",
        "img_width = 180\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-A3vm7X9K6S"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir,\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TjiuEo99O33"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  data_dir,\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBzxRDDl9SrG"
      },
      "source": [
        "class_names = train_ds.class_names\r\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUbmt6a9UOo"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "for images, labels in train_ds.take(1):\r\n",
        "  for i in range(9):\r\n",
        "    ax = plt.subplot(3, 3, i + 1)\r\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "    plt.title(class_names[labels[i]])\r\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiG1NphL9Ww9"
      },
      "source": [
        "for image_batch, labels_batch in train_ds:\r\n",
        "  print(image_batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZjjQ1R_9YWA"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\r\n",
        "\r\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\r\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXfo19Nf9bFM"
      },
      "source": [
        "num_classes = 2\r\n",
        "\r\n",
        "model = Sequential([\r\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\r\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n",
        "  layers.MaxPooling2D(),\r\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\r\n",
        "  layers.MaxPooling2D(),\r\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n",
        "  layers.MaxPooling2D(),\r\n",
        "  layers.Flatten(),\r\n",
        "  layers.Dense(128, activation='relu'),\r\n",
        "  layers.Dense(num_classes)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQxshnuf9dUE"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLY34_pu9ep5"
      },
      "source": [
        "model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKyEQKZ89fuH"
      },
      "source": [
        "epochs=10\r\n",
        "history = model.fit(\r\n",
        "  train_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=epochs\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}